{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "#apillay HW3P2 Notebook\n",
    "\n",
    "Note: This notebook version corresponds to run v3090-tc460-pb2.2_resume+config_change+augment but with its config modified a bit (like reduced batch size) to run inference on my laptop's GPU. The code is however exactly the same as my final run listed below\n",
    "\n",
    "WanDB link: https://wandb.ai/audio-idl/hw3p2-ablations?workspace=user-apillay\n",
    "Please find the following runs used to track the training for this work:\n",
    "1. v3090-tc100-pb2.2+embed_656: Trained from scratch on train-clean-100\n",
    "2. v3090-tc460-pb2.2_resume-3.6: Trained from previous model's best checkpoint on train-clean-460\n",
    "3. v3090-tc460-pb2.2_resume+config_change+augment: Trained from previous model's best checkpoint on increased data augmentation and lesser dropout/weight decay factors\n",
    "4. v3090-tc460-pb2.2_resume2+config_change+augment: Trained from previous model's best checkpoint as the VM crashed\n",
    "5. v3090-tc460-pb2.2_resume2_2.4+augmentations: Trained from previous model's best checkpoint with increased data augmentation factors\n",
    "6. v3090-tc460-pb2.2_resume3_2.3: Trained from previous model's best checkpoint as I discovered my model had room to get a better score on Kaggle lol\n",
    "\n",
    "Instructions to run the code:\n",
    "Run all cells in the following sequence!"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Installs"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONgAWhqdoYy-"
   },
   "source": [
    "### Levenshtein\n",
    "\n",
    "This may take a while"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SS7a7xeEoaV9",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install wandb --quiet\n",
    "!pip install python-Levenshtein -q\n",
    "!git clone --recursive https://github.com/parlance/ctcdecode.git\n",
    "!pip install wget -q\n",
    "%cd ctcdecode\n",
    "!pip install . -q\n",
    "%cd ..\n",
    "\n",
    "!pip install --upgrade --force-reinstall torchsummaryX\n",
    "!pip install pytorch-nlp\n",
    "!pip install slugify\n",
    "!pip install matplotlib\n",
    "!pip install --upgrade --force-reinstall pandas\n",
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IWVONJxCobPc"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "78ZTCIXoof2f",
    "outputId": "b741123a-7a4a-4558-a8c2-08f8a8121d81"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torchnlp.nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torchinfo import summary\n",
    "\n",
    "import torchaudio.transforms as tat\n",
    "\n",
    "import gc\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "# imports for decoding and distance calculation\n",
    "import Levenshtein\n",
    "from ctcdecode import CTCBeamDecoder\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "aOBCsPhr8J_E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri Apr  7 17:08:34 2023       \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 530.41.03              Driver Version: 530.41.03    CUDA Version: 12.1     |\r\n",
      "|-----------------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name                  Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf            Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                      |               MIG M. |\r\n",
      "|=========================================+======================+======================|\r\n",
      "|   0  NVIDIA GeForce RTX 3070 L...    Off| 00000000:01:00.0 Off |                  N/A |\r\n",
      "| N/A   42C    P3               N/A /  N/A|      8MiB /  8192MiB |      0%      Default |\r\n",
      "|                                         |                      |                  N/A |\r\n",
      "+-----------------------------------------+----------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                            |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\r\n",
      "|        ID   ID                                                             Usage      |\r\n",
      "|=======================================================================================|\r\n",
      "|    0   N/A  N/A       686      G   /usr/lib/Xorg                                 4MiB |\r\n",
      "+---------------------------------------------------------------------------------------+\r\n",
      "\r\n",
      "==============NVSMI LOG==============\r\n",
      "\r\n",
      "Timestamp                                 : Fri Apr  7 17:08:34 2023\r\n",
      "Driver Version                            : 530.41.03\r\n",
      "CUDA Version                              : 12.1\r\n",
      "\r\n",
      "Attached GPUs                             : 1\r\n",
      "GPU 00000000:01:00.0\r\n",
      "    Power Readings\r\n",
      "        Power Management                  : N/A\r\n",
      "        Power Draw                        : 25.94 W\r\n",
      "        Power Limit                       : N/A\r\n",
      "        Default Power Limit               : N/A\r\n",
      "        Enforced Power Limit              : N/A\r\n",
      "        Min Power Limit                   : N/A\r\n",
      "        Max Power Limit                   : N/A\r\n",
      "    Power Samples\r\n",
      "        Duration                          : Not Found\r\n",
      "        Number of Samples                 : Not Found\r\n",
      "        Max                               : Not Found\r\n",
      "        Min                               : Not Found\r\n",
      "        Avg                               : Not Found\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi\n",
    "!nvidia-smi -q -d POWER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gg3-yJ8tok34"
   },
   "source": [
    "# Kaggle Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AdUelfGhom1m"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade --force-reinstall --no-deps kaggle==1.5.8\n",
    "!rm -rf /root/.kaggle\n",
    "!mkdir /root/.kaggle\n",
    "\n",
    "with open(\"/root/.kaggle/kaggle.json\", \"w+\") as f:\n",
    "    f.write('{\"username\":\"ashwinpillay\",\"key\":\"<api>\"}')\n",
    "    # Put your kaggle username & key here\n",
    "\n",
    "!chmod 600 /root/.kaggle/kaggle.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dSjBwfXeoq4B"
   },
   "outputs": [],
   "source": [
    "!kaggle competitions download -c 11-785-s23-hw3p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "juPR8XSTFRH5"
   },
   "outputs": [],
   "source": [
    "!sudo apt-get install zip unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_ruxWP60LCQA"
   },
   "outputs": [],
   "source": [
    "'''\n",
    "This will take a couple minutes, but you should see at least the following:\n",
    "11-785-f22-hw3p2.zip  ctcdecode  hw3p2\n",
    "'''\n",
    "!unzip -q 11-785-s23-hw3p2.zip\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'batch_size': 8, # this is for my laptop GPU, user 64 for training on rtx3090\n",
    "    'epochs': 500,\n",
    "    'lr': 2e-3,\n",
    "    'ctc_decoder_train': {\n",
    "        'num_processes': 4,\n",
    "        'beam_width': 8,\n",
    "    },\n",
    "    'ctc_decoder_test': {\n",
    "        'num_processes': 4,\n",
    "        'beam_width': 16,\n",
    "    },\n",
    "    'rlrop_params': {\n",
    "        'factor': 0.75,\n",
    "        'patience': 4,\n",
    "        'threshold': 0.001,\n",
    "        'threshold_mode': 'rel',\n",
    "        'cooldown': 2,\n",
    "    },\n",
    "    'CA_lr_params': {\n",
    "        'T_max': 8,\n",
    "        'eta_min': 1e-6,\n",
    "    },\n",
    "    'dropout_p': 0.25,\n",
    "    'adamw_weight_decay': 1e-2,\n",
    "    'time_mask_maxl': 100,\n",
    "    'time_mask_p': 0.9,\n",
    "    'freq_mask_maxl': 5,\n",
    "    'num_workers_train': 6,\n",
    "    'num_workers_val': 2,\n",
    "    'num_workers_test': 2,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2ORNHnSFroP0"
   },
   "source": [
    "# Dataset and Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "k0v7wHRWrqH6"
   },
   "outputs": [],
   "source": [
    "# ARPABET PHONEME MAPPING\n",
    "# DO NOT CHANGE\n",
    "# This overwrites the phonetics.py file.\n",
    "\n",
    "CMUdict_ARPAbet = {\n",
    "    \"\": \" \",\n",
    "    \"[SIL]\": \"-\", \"NG\": \"G\", \"F\": \"f\", \"M\": \"m\", \"AE\": \"@\",\n",
    "    \"R\": \"r\", \"UW\": \"u\", \"N\": \"n\", \"IY\": \"i\", \"AW\": \"W\",\n",
    "    \"V\": \"v\", \"UH\": \"U\", \"OW\": \"o\", \"AA\": \"a\", \"ER\": \"R\",\n",
    "    \"HH\": \"h\", \"Z\": \"z\", \"K\": \"k\", \"CH\": \"C\", \"W\": \"w\",\n",
    "    \"EY\": \"e\", \"ZH\": \"Z\", \"T\": \"t\", \"EH\": \"E\", \"Y\": \"y\",\n",
    "    \"AH\": \"A\", \"B\": \"b\", \"P\": \"p\", \"TH\": \"T\", \"DH\": \"D\",\n",
    "    \"AO\": \"c\", \"G\": \"g\", \"L\": \"l\", \"JH\": \"j\", \"OY\": \"O\",\n",
    "    \"SH\": \"S\", \"D\": \"d\", \"AY\": \"Y\", \"S\": \"s\", \"IH\": \"I\",\n",
    "    \"[SOS]\": \"[SOS]\", \"[EOS]\": \"[EOS]\"\n",
    "}\n",
    "\n",
    "CMUdict = list(CMUdict_ARPAbet.keys())\n",
    "ARPAbet = list(CMUdict_ARPAbet.values())\n",
    "\n",
    "PHONEMES = CMUdict[:-2]\n",
    "LABELS = ARPAbet[:-2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "agmNBKf4JrLV"
   },
   "source": [
    "### Train Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cepstral_normalize(mfcc):\n",
    "    mean_mfcc = np.mean(mfcc, axis=0)\n",
    "    std_mfcc = np.std(mfcc, axis=0) + np.finfo('float').eps\n",
    "    normalized_mfcc = (mfcc - mean_mfcc) / std_mfcc\n",
    "    return normalized_mfcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utils for network\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "class PermuteBlock(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, root1='.', root2=None):\n",
    "        '''\n",
    "        Initializes the dataset.\n",
    "        '''\n",
    "\n",
    "        self.mfcc_paths, self.transcript_paths = [], []\n",
    "        self.PHONEMES = PHONEMES\n",
    "\n",
    "        self.augmentations = torch.nn.Sequential(\n",
    "            PermuteBlock(),\n",
    "            tat.TimeMasking(time_mask_param=config['time_mask_maxl'], p=config['time_mask_p']),\n",
    "            tat.FrequencyMasking(freq_mask_param=config['freq_mask_maxl']),\n",
    "            PermuteBlock(),\n",
    "        )\n",
    "\n",
    "        roots = [root1]\n",
    "        if root2 is not None:\n",
    "            roots.append(root2)\n",
    "\n",
    "        for root in roots:\n",
    "            print(\"=> Loading paths from: {}\".format(root))\n",
    "            mfcc_dir = os.path.join(root, 'mfcc')\n",
    "            transcript_dir = os.path.join(root, 'transcript')\n",
    "\n",
    "            mfcc_files = sorted(os.listdir(mfcc_dir))\n",
    "            transcript_files = sorted(os.listdir(transcript_dir))\n",
    "\n",
    "            root_file_length = len(mfcc_files)\n",
    "            for i in tqdm(range(root_file_length)):\n",
    "                self.mfcc_paths.append(os.path.join(root, 'mfcc', mfcc_files[i]))\n",
    "                self.transcript_paths.append(os.path.join(root, 'transcript', transcript_files[i]))\n",
    "        # Train Dataset only initializes with path to reduce CPU RAM usage (empirically found that fetching data during __getitem__ is not too costly!\n",
    "\n",
    "        assert len(self.mfcc_paths) == len(self.transcript_paths)\n",
    "        self.length = len(self.mfcc_paths)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        '''\n",
    "        Return a tuple of features and labels.\n",
    "        '''\n",
    "        return self.mfcc_paths[ind], self.transcript_paths[ind]\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        '''\n",
    "        1.  Extract the features and labels from 'batch'\n",
    "        2.  We will additionally need to pad both features and labels,\n",
    "            look at pytorch's docs for pad_sequence\n",
    "        3.  This is a good place to perform transforms, if you so wish.\n",
    "            Performing them on batches will speed the process up a bit.\n",
    "        4.  Return batch of features, labels, lenghts of features,\n",
    "            and lengths of labels.\n",
    "        '''\n",
    "\n",
    "        # batch of input mfcc coefficients\n",
    "        batch_mfcc_paths = [bitem[0] for bitem in batch]\n",
    "\n",
    "        # batch of output phonemes\n",
    "        batch_transcript_paths = [bitem[1] for bitem in batch]\n",
    "\n",
    "        batch_mfcc, batch_transcript = [], []\n",
    "        for mffc_ind in range(len(batch_mfcc_paths)):\n",
    "            mfcc = np.load(batch_mfcc_paths[mffc_ind])\n",
    "            mfcc = cepstral_normalize(mfcc)\n",
    "            mfcc = torch.FloatTensor(mfcc)\n",
    "            batch_mfcc.append(mfcc)\n",
    "\n",
    "            transcript = np.load(batch_transcript_paths[mffc_ind])[1:-1]\n",
    "            transcript_maps = [self.PHONEMES.index(j) for j in transcript]\n",
    "            transcript = torch.tensor(transcript_maps)\n",
    "            batch_transcript.append(transcript)\n",
    "\n",
    "        lengths_mfcc = [len(mfcc_i) for mfcc_i in batch_mfcc]\n",
    "\n",
    "        lengths_transcript = [len(transcript_i) for transcript_i in batch_transcript]\n",
    "\n",
    "        batch_mfcc_pad = pad_sequence(batch_mfcc, batch_first=True)\n",
    "        batch_transcript_pad = pad_sequence(batch_transcript, batch_first=True)\n",
    "\n",
    "        batch_mfcc_pad = self.augmentations(batch_mfcc_pad)\n",
    "\n",
    "        # Return the following values: padded features, padded labels, actual length of features, actual length of the labels\n",
    "        return batch_mfcc_pad, batch_transcript_pad, torch.tensor(lengths_mfcc), torch.tensor(lengths_transcript)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Validation Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDatasetValidate(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, root1='.', root2=None):\n",
    "        '''\n",
    "        Initializes the dataset.\n",
    "\n",
    "        '''\n",
    "\n",
    "        # Load the directory and all files in them\n",
    "\n",
    "        self.mfccs, self.transcripts = [], []\n",
    "        self.PHONEMES = PHONEMES\n",
    "\n",
    "        roots = [root1]\n",
    "        if root2 is not None:\n",
    "            roots.append(root2)\n",
    "\n",
    "        for root in roots:\n",
    "            print(\"=> Loading from: {}\".format(root))\n",
    "            mfcc_dir = os.path.join(root, 'mfcc')\n",
    "            transcript_dir = os.path.join(root, 'transcript')\n",
    "\n",
    "            mfcc_files = sorted(os.listdir(mfcc_dir))\n",
    "            transcript_files = sorted(os.listdir(transcript_dir))\n",
    "\n",
    "            root_file_length = len(mfcc_files)\n",
    "            for i in tqdm(range(root_file_length)):\n",
    "                mfcc = np.load(os.path.join(root, 'mfcc', mfcc_files[i]))\n",
    "                mfcc = cepstral_normalize(mfcc)\n",
    "                self.mfccs.append(mfcc)\n",
    "\n",
    "                transcript = np.load(os.path.join(root, 'transcript', transcript_files[i]))[1:-1]\n",
    "                transcript_maps = [self.PHONEMES.index(j) for j in transcript]\n",
    "                self.transcripts.append(transcript_maps)\n",
    "\n",
    "        assert len(self.mfccs) == len(self.transcripts)\n",
    "        self.length = len(self.mfccs)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        '''\n",
    "        Return a tuple of features and labels.\n",
    "        '''\n",
    "        mfcc = torch.FloatTensor(self.mfccs[ind])\n",
    "        transcript = torch.tensor(self.transcripts[ind])\n",
    "        return mfcc, transcript\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        '''\n",
    "        1.  Extract the features and labels from 'batch'\n",
    "        2.  We will additionally need to pad both features and labels,\n",
    "            look at pytorch's docs for pad_sequence\n",
    "        3.  This is a good place to perform transforms, if you so wish.\n",
    "            Performing them on batches will speed the process up a bit.\n",
    "        4.  Return batch of features, labels, lenghts of features,\n",
    "            and lengths of labels.\n",
    "        '''\n",
    "        # batch of input mfcc coefficients\n",
    "\n",
    "        batch_mfcc = [bitem[0] for bitem in batch]\n",
    "\n",
    "        # batch of output phonemes\n",
    "        batch_transcript = [bitem[1] for bitem in batch]\n",
    "\n",
    "        batch_mfcc_pad = pad_sequence(batch_mfcc, batch_first=True)\n",
    "        lengths_mfcc = [len(mfcc_i) for mfcc_i in batch_mfcc]\n",
    "\n",
    "        batch_transcript_pad = pad_sequence(batch_transcript, batch_first=True)\n",
    "        lengths_transcript = [len(transcript_i) for transcript_i in batch_transcript]\n",
    "\n",
    "        # Return the following values: padded features, padded labels, actual length of features, actual length of the labels\n",
    "        return batch_mfcc_pad, batch_transcript_pad, torch.tensor(lengths_mfcc), torch.tensor(lengths_transcript)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AudioDatasetTest(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, root='.'):\n",
    "        '''\n",
    "        Initializes the dataset.\n",
    "\n",
    "        INPUTS: What inputs do you need here?\n",
    "        '''\n",
    "\n",
    "        # Load the directory and all files in them\n",
    "\n",
    "        self.mfcc_dir = os.path.join(root, 'mfcc')\n",
    "\n",
    "        self.mfcc_files = sorted(os.listdir(self.mfcc_dir))\n",
    "\n",
    "        self.PHONEMES = PHONEMES\n",
    "\n",
    "        self.length = len(self.mfcc_files)\n",
    "\n",
    "        self.mfccs = []\n",
    "        for i in tqdm(range(self.length)):\n",
    "            mfcc = np.load(os.path.join(root, 'mfcc', self.mfcc_files[i]))\n",
    "            mfcc = cepstral_normalize(mfcc)\n",
    "            self.mfccs.append(mfcc)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "    def __getitem__(self, ind):\n",
    "        '''\n",
    "        Return a tuple of features and labels.\n",
    "        '''\n",
    "\n",
    "        mfcc = torch.FloatTensor(self.mfccs[ind])\n",
    "        return mfcc\n",
    "\n",
    "    def collate_fn(self, batch):\n",
    "        '''\n",
    "        1.  Extract the features and labels from 'batch'\n",
    "        2.  We will additionally need to pad both features and labels,\n",
    "            look at pytorch's docs for pad_sequence\n",
    "        3.  This is a good place to perform transforms, if you so wish.\n",
    "            Performing them on batches will speed the process up a bit.\n",
    "        4.  Return batch of features, labels, lenghts of features,\n",
    "            and lengths of labels.\n",
    "        '''\n",
    "        # batch of input mfcc coefficients\n",
    "\n",
    "        batch_mfcc = batch\n",
    "\n",
    "        batch_mfcc_pad = pad_sequence(batch_mfcc, batch_first=True)\n",
    "        lengths_mfcc = [len(mfcc_i) for mfcc_i in batch_mfcc]\n",
    "\n",
    "        # Return the following values: padded features, actual length of features\n",
    "        return batch_mfcc_pad, torch.tensor(lengths_mfcc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data - Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Train Dataset: \n",
      "=> Loading paths from: ./11-785-s23-hw3p2/train-clean-100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28539/28539 [00:00<00:00, 534042.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Val Dataset: \n",
      "=> Loading from: ./11-785-s23-hw3p2/dev-clean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2703/2703 [00:02<00:00, 1266.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Test Dataset: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2620/2620 [00:01<00:00, 1828.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Batch size:  32\n",
      "Train dataset samples = 28539, batches = 892\n",
      "Val dataset samples = 2703, batches = 85\n",
      "Test dataset samples = 2620, batches = 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Create objects for the dataset class\n",
    "print(\"Loading Train Dataset: \")\n",
    "train_data = AudioDataset(root1='./11-785-s23-hw3p2/train-clean-100')\n",
    "\n",
    "print(\"Loading Val Dataset: \")\n",
    "val_data = AudioDatasetValidate(root1='./11-785-s23-hw3p2/dev-clean')\n",
    "\n",
    "print(\"Loading Test Dataset: \")\n",
    "test_data = AudioDatasetTest(root='./11-785-s23-hw3p2/test-clean')\n",
    "\n",
    "# Do NOT forget to pass in the collate function as parameter while creating the dataloader\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    dataset=train_data,\n",
    "    collate_fn=train_data.collate_fn,\n",
    "    num_workers=config['num_workers_train'],\n",
    "    batch_size=config['batch_size'],\n",
    "    pin_memory=True,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset=val_data,\n",
    "    collate_fn=val_data.collate_fn,\n",
    "    num_workers=config['num_workers_val'],\n",
    "    batch_size=config['batch_size'],\n",
    "    pin_memory=True,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_data,\n",
    "    collate_fn=test_data.collate_fn,\n",
    "    num_workers=config['num_workers_test'],\n",
    "    batch_size=config['batch_size'],\n",
    "    pin_memory=True,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "print(\"\\nBatch size: \", config['batch_size'])\n",
    "print(\"Train dataset samples = {}, batches = {}\".format(train_data.__len__(), len(train_loader)))\n",
    "print(\"Val dataset samples = {}, batches = {}\".format(val_data.__len__(), len(val_loader)))\n",
    "print(\"Test dataset samples = {}, batches = {}\".format(test_data.__len__(), len(test_loader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del train_loader, val_loader, test_loader\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1654, 27]) torch.Size([32, 202]) torch.Size([32]) torch.Size([32])\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for data in train_loader:\n",
    "    x, y, lx, ly = data\n",
    "    print(x.shape, y.shape, lx.shape, ly.shape)\n",
    "    # Plots train data with its augmentations\n",
    "    plt.imshow(x[0].T, interpolation='nearest', aspect='auto', cmap='viridis')\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NETWORK: Pyramid Bi-LSTM (pBLSTM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "TsQRmZXq3Yao"
   },
   "outputs": [],
   "source": [
    "class Resnet34ResidualBlock1d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, kernel_size=3, padding=1):\n",
    "        super(Resnet34ResidualBlock1d, self).__init__()\n",
    "        self.cnn1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "            nn.BatchNorm1d(out_channels),\n",
    "            nn.ReLU(True)\n",
    "        )\n",
    "        self.cnn2 = nn.Sequential(\n",
    "            nn.Conv1d(out_channels, out_channels, kernel_size, 1, padding, bias=False),\n",
    "            nn.BatchNorm1d(out_channels)\n",
    "        )\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm1d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.shortcut = nn.Sequential()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.cnn1(x)\n",
    "        x = self.cnn2(x)\n",
    "        x += self.shortcut(residual)\n",
    "        x = nn.ReLU(True)(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "3xkc_Mfz3Yap"
   },
   "outputs": [],
   "source": [
    "class pBLSTM(torch.nn.Module):\n",
    "    '''\n",
    "    Pyramidal BiLSTM\n",
    "    Read the writeup/paper and understand the concepts and then write your implementation here.\n",
    "\n",
    "    At each step,\n",
    "    1. Pad your input if it is packed (Unpack it)\n",
    "    2. Reduce the input length dimension by concatenating feature dimension\n",
    "        (Tip: Write down the shapes and understand)\n",
    "        (i) How should  you deal with odd/even length input?\n",
    "        (ii) How should you deal with input length array (x_lens) after truncating the input?\n",
    "    3. Pack your input\n",
    "    4. Pass it into LSTM layer\n",
    "\n",
    "    To make our implementation modular, we pass 1 layer at a time.\n",
    "    '''\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, n_lstm=1):\n",
    "        super(pBLSTM, self).__init__()\n",
    "\n",
    "        self.ld = torchnlp.nn.LockedDropout(p=config['dropout_p'])\n",
    "\n",
    "        self.ln = nn.LayerNorm(input_size * 2, eps=1e-06)\n",
    "\n",
    "        self.blstm = nn.LSTM(input_size=input_size * 2, hidden_size=hidden_size, num_layers=n_lstm, bidirectional=True,\n",
    "                             batch_first=True)\n",
    "\n",
    "    def forward(self, x_packed):  # x_packed is a PackedSequence\n",
    "\n",
    "        # Pad Packed Sequence\n",
    "        x, x_lens = pad_packed_sequence(x_packed, batch_first=True, padding_value=0.0)\n",
    "\n",
    "        x, x_lens = self.trunc_reshape(x, x_lens)\n",
    "\n",
    "        x = torch.permute(x, (1, 0, 2))\n",
    "        x = self.ld(x)\n",
    "        x = self.ln(x)\n",
    "        x = torch.permute(x, (1, 0, 2))\n",
    "\n",
    "        # Pack Padded Sequence.\n",
    "        x = pack_padded_sequence(x, lengths=x_lens, batch_first=True, enforce_sorted=False)\n",
    "\n",
    "        # Pass the sequence through bLSTM\n",
    "        x, _ = self.blstm(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def trunc_reshape(self, x, x_lens):\n",
    "        if x.size(dim=1) % 2 == 1:\n",
    "            x = x[:, :-1, :]\n",
    "        x = x.reshape(x.shape[0], x.shape[1] // 2, x.shape[2] * 2)\n",
    "        x_lens //= 2\n",
    "        return x, x_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "R3jWDGGs3Yap"
   },
   "outputs": [],
   "source": [
    "class Encoder(torch.nn.Module):\n",
    "    '''\n",
    "    The Encoder takes utterances as inputs and returns latent feature representations\n",
    "    '''\n",
    "\n",
    "    def __init__(self, input_size=27, encoder_hidden_size=256):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.embedding_stride = 1\n",
    "        self.embedding_kernel_size = 3\n",
    "        self.embedding_padding = 1\n",
    "\n",
    "        self.embedding = nn.Sequential(\n",
    "            PermuteBlock(),\n",
    "            Resnet34ResidualBlock1d(in_channels=input_size, out_channels=1024, stride=self.embedding_stride,\n",
    "                                    kernel_size=self.embedding_kernel_size, padding=self.embedding_padding),\n",
    "            PermuteBlock(),\n",
    "        )\n",
    "\n",
    "        self.pBLSTMs = nn.Sequential(\n",
    "            pBLSTM(input_size=1024, hidden_size=encoder_hidden_size, n_lstm=2),\n",
    "            pBLSTM(input_size=encoder_hidden_size * 2, hidden_size=encoder_hidden_size, n_lstm=2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, x_lens):\n",
    "        # Call the embedding layer\n",
    "        x = self.embedding(x)\n",
    "        x_lens = (x_lens - self.embedding_kernel_size + 2 * self.embedding_padding) // self.embedding_stride\n",
    "\n",
    "        # Pack Padded Sequence\n",
    "        x = pack_padded_sequence(x, lengths=x_lens, batch_first=True, enforce_sorted=False)\n",
    "\n",
    "        # Pass Sequence through the pyramidal Bi-LSTM layer\n",
    "        x = self.pBLSTMs(x)\n",
    "\n",
    "        # Pad Packed Sequence\n",
    "        encoder_outputs, encoder_lens = pad_packed_sequence(x, batch_first=True, padding_value=0.0)\n",
    "\n",
    "        return encoder_outputs, encoder_lens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kg82HXa3MUz1"
   },
   "source": [
    "# Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "fxPzpxJh3Yap"
   },
   "outputs": [],
   "source": [
    "class DecoderLinear(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_size, last_layer=False):\n",
    "        super(DecoderLinear, self).__init__()\n",
    "\n",
    "        if last_layer:\n",
    "            self.model = torch.nn.Sequential(\n",
    "                PermuteBlock(),\n",
    "                nn.BatchNorm1d(input_size),\n",
    "                PermuteBlock(),\n",
    "                nn.Linear(input_size, output_size),\n",
    "            )\n",
    "        else:\n",
    "            self.model = torch.nn.Sequential(\n",
    "                PermuteBlock(),\n",
    "                nn.BatchNorm1d(input_size),\n",
    "                PermuteBlock(),\n",
    "                nn.Linear(input_size, output_size),\n",
    "                nn.GELU(),\n",
    "                nn.Dropout(p=config['dropout_p']),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.model(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "4u3hOOD53Yap"
   },
   "outputs": [],
   "source": [
    "class Decoder(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, embed_size=256 * 2, output_size=len(LABELS)):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mlp = torch.nn.Sequential(\n",
    "            DecoderLinear(input_size=embed_size, output_size=embed_size // 2),\n",
    "            DecoderLinear(input_size=embed_size // 2, output_size=embed_size // 4),\n",
    "            DecoderLinear(input_size=embed_size // 4, output_size=output_size, last_layer=True),\n",
    "        )\n",
    "\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "\n",
    "    def forward(self, encoder_out):\n",
    "        out = self.mlp(encoder_out)\n",
    "        out = self.softmax(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "qmHf6pFiMUz1"
   },
   "outputs": [],
   "source": [
    "class ASRModel(torch.nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, embed_size=256, output_size=len(LABELS)):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(input_size=input_size, encoder_hidden_size=embed_size)\n",
    "        self.decoder = Decoder(embed_size=embed_size * 2, output_size=output_size)\n",
    "\n",
    "    def forward(self, x, lengths_x):\n",
    "        encoder_out, encoder_lens = self.encoder(x, lengths_x)\n",
    "        decoder_out = self.decoder(encoder_out)\n",
    "\n",
    "        return decoder_out, encoder_lens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EV7DMPDoMUz2"
   },
   "source": [
    "## INIT ASR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "oaaDsnnLMUz2",
    "outputId": "66316fb2-3d1d-4f9f-d38a-d88f01c51e05"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASRModel(\n",
      "  (encoder): Encoder(\n",
      "    (embedding): Sequential(\n",
      "      (0): PermuteBlock()\n",
      "      (1): Resnet34ResidualBlock1d(\n",
      "        (cnn1): Sequential(\n",
      "          (0): Conv1d(27, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "        )\n",
      "        (cnn2): Sequential(\n",
      "          (0): Conv1d(1024, 1024, kernel_size=(3,), stride=(1,), padding=(1,), bias=False)\n",
      "          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "        (shortcut): Sequential(\n",
      "          (0): Conv1d(27, 1024, kernel_size=(1,), stride=(1,), bias=False)\n",
      "          (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (2): PermuteBlock()\n",
      "    )\n",
      "    (pBLSTMs): Sequential(\n",
      "      (0): pBLSTM(\n",
      "        (ld): LockedDropout(p=0.25)\n",
      "        (ln): LayerNorm((2048,), eps=1e-06, elementwise_affine=True)\n",
      "        (blstm): LSTM(2048, 656, num_layers=2, batch_first=True, bidirectional=True)\n",
      "      )\n",
      "      (1): pBLSTM(\n",
      "        (ld): LockedDropout(p=0.25)\n",
      "        (ln): LayerNorm((2624,), eps=1e-06, elementwise_affine=True)\n",
      "        (blstm): LSTM(2624, 656, num_layers=2, batch_first=True, bidirectional=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (mlp): Sequential(\n",
      "      (0): DecoderLinear(\n",
      "        (model): Sequential(\n",
      "          (0): PermuteBlock()\n",
      "          (1): BatchNorm1d(1312, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): PermuteBlock()\n",
      "          (3): Linear(in_features=1312, out_features=656, bias=True)\n",
      "          (4): GELU(approximate='none')\n",
      "          (5): Dropout(p=0.25, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): DecoderLinear(\n",
      "        (model): Sequential(\n",
      "          (0): PermuteBlock()\n",
      "          (1): BatchNorm1d(656, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): PermuteBlock()\n",
      "          (3): Linear(in_features=656, out_features=328, bias=True)\n",
      "          (4): GELU(approximate='none')\n",
      "          (5): Dropout(p=0.25, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (2): DecoderLinear(\n",
      "        (model): Sequential(\n",
      "          (0): PermuteBlock()\n",
      "          (1): BatchNorm1d(328, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): PermuteBlock()\n",
      "          (3): Linear(in_features=328, out_features=41, bias=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (softmax): LogSoftmax(dim=2)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": "======================================================================\nLayer (type:depth-idx)                        Param #\n======================================================================\nASRModel                                      --\n├─Encoder: 1-1                                --\n│    └─Sequential: 2-1                        --\n│    │    └─PermuteBlock: 3-1                 --\n│    │    └─Resnet34ResidualBlock1d: 3-2      3,262,464\n│    │    └─PermuteBlock: 3-3                 --\n│    └─Sequential: 2-2                        --\n│    │    └─pBLSTM: 3-4                       24,543,744\n│    │    └─pBLSTM: 3-5                       27,567,744\n├─Decoder: 1-2                                --\n│    └─Sequential: 2-3                        --\n│    │    └─DecoderLinear: 3-6                863,952\n│    │    └─DecoderLinear: 3-7                216,808\n│    │    └─DecoderLinear: 3-8                14,145\n│    └─LogSoftmax: 2-4                        --\n======================================================================\nTotal params: 56,468,857\nTrainable params: 56,468,857\nNon-trainable params: 0\n======================================================================"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "model = ASRModel(\n",
    "    input_size=27,\n",
    "    embed_size=656,\n",
    "    output_size=len(LABELS)\n",
    ").to(device)\n",
    "print(model)\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "3A3sTSGMgzit"
   },
   "outputs": [],
   "source": [
    "# del model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IBwunYpyugFg"
   },
   "source": [
    "# Training Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "iGoozH2nd6KB"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CTCLoss(blank=0, zero_infinity=False)\n",
    "# CTC Loss: https://pytorch.org/docs/stable/generated/torch.nn.CTCLoss.html\n",
    "# Refer to the handout for hints\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config['lr'], weight_decay=config['adamw_weight_decay'])\n",
    "\n",
    "# Declare the decoder. Use the CTC Beam Decoder to decode phonemes\n",
    "decoder = CTCBeamDecoder(LABELS, log_probs_input=True, **config['ctc_decoder_train'])\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, **config['CA_lr_params'])\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, **config['rlrop_params'])\n",
    "\n",
    "# Mixed Precision, if you need it\n",
    "scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F3mdQlSUiMi9"
   },
   "outputs": [],
   "source": [
    "# del criterion, optimizer, decoder, scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jmc6_4eWL2Xp"
   },
   "source": [
    "## Decode Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "KHjnCDddL36E"
   },
   "outputs": [],
   "source": [
    "npLABELS = np.asarray(LABELS)\n",
    "\n",
    "\n",
    "def decode_prediction(output, output_lens, decoder, PHONEME_MAP=npLABELS):\n",
    "    beam_results, beam_scores, timesteps, output_lens = decoder.decode(output,\n",
    "                                                                       seq_lens=output_lens)  #lengths - list of lengths\n",
    "\n",
    "    pred_strings = []\n",
    "\n",
    "    for i in range(output_lens.shape[0]):\n",
    "        top_beam = beam_results[i][0][:output_lens[i][0]].numpy()\n",
    "        pred_strings.append(''.join(PHONEME_MAP[top_beam]))\n",
    "\n",
    "    return pred_strings\n",
    "\n",
    "\n",
    "def calculate_levenshtein(output, label, output_lens, label_lens, decoder,\n",
    "                          PHONEME_MAP=npLABELS):  # y - sequence of integers\n",
    "\n",
    "    dist = 0\n",
    "    batch_size = label.shape[0]\n",
    "\n",
    "    pred_strings = decode_prediction(output, output_lens, decoder, PHONEME_MAP)\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        pred_string = pred_strings[i]\n",
    "        label_string = ''.join(PHONEME_MAP[label.cpu()[i, :label_lens[i]].numpy()])\n",
    "        # print(\"P = {}; L = {}\".format(pred_string, label_string))\n",
    "        dist += Levenshtein.distance(pred_string, label_string)\n",
    "\n",
    "    dist /= batch_size\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GnTLL-5gMBrY",
    "outputId": "0b9cdfa9-ece7-4225-8731-eb98c4454f9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2936, 27])\n",
      "torch.Size([32])\n",
      "torch.Size([32, 733, 41])\n",
      "torch.Size([733, 32, 41]) torch.Size([32, 265])\n",
      "tensor(7.6047, device='cuda:0', grad_fn=<MeanBackward0>)\n",
      "65.4375\n"
     ]
    }
   ],
   "source": [
    "# test code to check shapes\n",
    "\n",
    "model.eval()\n",
    "for i, data in enumerate(val_loader, 0):\n",
    "    x, y, lx, ly = data\n",
    "    print(x.shape)\n",
    "    print(lx.shape)\n",
    "    x, y = x.to(device), y.to(device)\n",
    "    h, lh = model(x, lx)\n",
    "    print(h.shape)\n",
    "    h = torch.permute(h, (1, 0, 2))\n",
    "    print(h.shape, y.shape)\n",
    "    loss = criterion(h, y, lh, ly)\n",
    "    print(loss)\n",
    "\n",
    "    h = torch.permute(h, (1, 0, 2))\n",
    "    print(calculate_levenshtein(h, y, lh, ly, decoder, npLABELS))\n",
    "\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rd5aNaLVoR_g"
   },
   "source": [
    "## wandb\n",
    "\n",
    "You will need to fetch your api key from wandb.ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PiDduMaDIARE",
    "outputId": "bdf2b4d0-4ef4-4767-ab6d-bfdb23c090d4"
   },
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login(key=\"<api>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "id": "4s52yBOvICPZ",
    "outputId": "f9ea81d6-8288-4cd8-9a95-15a29195d5b2"
   },
   "outputs": [],
   "source": [
    "run = wandb.init(\n",
    "    name=\"v3090-tc460-pb2.2_resume+config_change+augment\",  ## Wandb creates random run names if you skip this field\n",
    "    reinit=True,  ### Allows reinitalizing runs when you re-run this cell\n",
    "    # run_id = ### Insert specific run id here if you want to resume a previous run\n",
    "    # resume = \"must\" ### You need this to resume previous runs, but comment out reinit = True when using this\n",
    "    project=\"hw3p2-ablations\",  ### Project should be created in your wandb account\n",
    "    config=config  ### Wandb Config for your run\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6fLLj5KIMMOe"
   },
   "source": [
    "# Train Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ri87MAdhMUz5"
   },
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer):\n",
    "    model.train()\n",
    "    batch_bar = tqdm(total=len(train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train')\n",
    "\n",
    "    total_loss = 0\n",
    "\n",
    "    for i, data in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        x, y, lx, ly = data\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        with torch.cuda.amp.autocast():\n",
    "            h, lh = model(x, lx)\n",
    "            h = torch.permute(h, (1, 0, 2))\n",
    "            loss = criterion(h.to(torch.float64), y, lh, ly)\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        batch_bar.set_postfix(\n",
    "            loss=\"{:.04f}\".format(float(total_loss / (i + 1))),\n",
    "            lr=\"{:.06f}\".format(float(optimizer.param_groups[0]['lr'])))\n",
    "\n",
    "        batch_bar.update()  # Update tqdm bar\n",
    "\n",
    "        # Another couple things you need for FP16. \n",
    "        scaler.scale(loss).backward()  # This is a replacement for loss.backward()\n",
    "        scaler.step(optimizer)  # This is a replacement for optimizer.step()\n",
    "        scaler.update()  # This is something added just for FP16\n",
    "\n",
    "        del x, y, lx, ly, h, lh, loss\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    batch_bar.close()  # You need this to close the tqdm bar\n",
    "\n",
    "    return total_loss / len(train_loader)\n",
    "\n",
    "\n",
    "def validate_model(model, val_loader, decoder, phoneme_map=LABELS):\n",
    "    model.eval()\n",
    "    batch_bar = tqdm(total=len(val_loader), dynamic_ncols=True, position=0, leave=False, desc='Val')\n",
    "\n",
    "    total_loss = 0\n",
    "    vdist = 0\n",
    "\n",
    "    for i, data in enumerate(val_loader):\n",
    "        x, y, lx, ly = data\n",
    "        x, y = x.to(device), y.to(device)\n",
    "\n",
    "        with torch.inference_mode():\n",
    "            h, lh = model(x, lx)\n",
    "            h = torch.permute(h, (1, 0, 2))\n",
    "            loss = criterion(h, y, lh, ly)\n",
    "\n",
    "        total_loss += float(loss)\n",
    "        vdist += calculate_levenshtein(torch.permute(h, (1, 0, 2)), y, lh, ly, decoder, phoneme_map)\n",
    "\n",
    "        batch_bar.set_postfix(loss=\"{:.04f}\".format(float(total_loss / (i + 1))),\n",
    "                              dist=\"{:.04f}\".format(float(vdist / (i + 1))))\n",
    "\n",
    "        batch_bar.update()\n",
    "\n",
    "        del x, y, lx, ly, h, lh, loss\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    batch_bar.close()\n",
    "    total_loss = total_loss / len(val_loader)\n",
    "    val_dist = vdist / len(val_loader)\n",
    "    return total_loss, val_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qpYExu4vT4_g"
   },
   "source": [
    "### Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "husa5_EYMUz6"
   },
   "outputs": [],
   "source": [
    "def save_model(model, optimizer, scheduler, metric, epoch, path):\n",
    "    torch.save(\n",
    "        {'model_state_dict': model.state_dict(),\n",
    "         'optimizer_state_dict': optimizer.state_dict(),\n",
    "         'scheduler_state_dict': scheduler.state_dict(),\n",
    "         metric[0]: metric[1],\n",
    "         'epoch': epoch},\n",
    "        path\n",
    "    )\n",
    "\n",
    "\n",
    "def load_model(path, model, metric='valid_dist', optimizer=None, scheduler=None):\n",
    "    checkpoint = torch.load(path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    if optimizer != None:\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "    if scheduler != None:\n",
    "        scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
    "\n",
    "    epoch = checkpoint['epoch']\n",
    "    metric = checkpoint[metric]\n",
    "\n",
    "    return [model, optimizer, scheduler, epoch, metric]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "tExvyl1BIdMC"
   },
   "outputs": [],
   "source": [
    "# This is for checkpointing, if you're doing it over multiple sessions\n",
    "\n",
    "last_epoch_completed = 0\n",
    "start = last_epoch_completed\n",
    "end = config[\"epochs\"]\n",
    "best_lev_dist = float(\"inf\")  # if you're restarting from some checkpoint, use what you saw there.\n",
    "epoch_model_path = './checkpoint_epoch.pth'\n",
    "best_model_path = './checkpoint_best.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "======================================================================\nLayer (type:depth-idx)                        Param #\n======================================================================\nASRModel                                      --\n├─Encoder: 1-1                                --\n│    └─Sequential: 2-1                        --\n│    │    └─PermuteBlock: 3-1                 --\n│    │    └─Resnet34ResidualBlock1d: 3-2      3,262,464\n│    │    └─PermuteBlock: 3-3                 --\n│    └─Sequential: 2-2                        --\n│    │    └─pBLSTM: 3-4                       24,543,744\n│    │    └─pBLSTM: 3-5                       27,567,744\n├─Decoder: 1-2                                --\n│    └─Sequential: 2-3                        --\n│    │    └─DecoderLinear: 3-6                863,952\n│    │    └─DecoderLinear: 3-7                216,808\n│    │    └─DecoderLinear: 3-8                14,145\n│    └─LogSoftmax: 2-4                        --\n======================================================================\nTotal params: 56,468,857\nTrainable params: 56,468,857\nNon-trainable params: 0\n======================================================================"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model, _, _, _, best_lev_dist = load_model('./checkpoint_epoch_fin.pth', model, 'valid_dist')\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PVB3yK4R3Yas",
    "outputId": "c45ba2c8-5808-4423-a39f-bb86fcdd7a4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'batch_size': 32, 'epochs': 500, 'lr': 0.002, 'ctc_decoder_train': {'num_processes': 4, 'beam_width': 8}, 'ctc_decoder_test': {'num_processes': 4, 'beam_width': 50}, 'rlrop_params': {'factor': 0.75, 'patience': 4, 'threshold': 0.001, 'threshold_mode': 'rel', 'cooldown': 2}, 'CA_lr_params': {'T_max': 8, 'eta_min': 1e-06}, 'dropout_p': 0.25, 'adamw_weight_decay': 0.01, 'time_mask_maxl': 100, 'time_mask_p': 0.9, 'freq_mask_maxl': 5, 'num_workers_train': 6, 'num_workers_val': 2, 'num_workers_test': 2}\n"
     ]
    },
    {
     "data": {
      "text/plain": "9"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(config)\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JR43E28rM9Ak",
    "outputId": "a5785e15-e837-467f-c079-1336e92d7967"
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "torch.autograd.set_detect_anomaly(False)\n",
    "\n",
    "for epoch in range(0, config['epochs']):\n",
    "\n",
    "    print(\"\\nEpoch: {}/{}\".format(epoch + 1, config['epochs']))\n",
    "\n",
    "    curr_lr = float(optimizer.param_groups[0]['lr'])\n",
    "\n",
    "    train_loss = train_model(model, train_loader, criterion, optimizer)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    w0grad = list(model.named_parameters())[0][1].grad.data[0][0][0].item()\n",
    "\n",
    "    print(\"Epoch {}/{}: Train Loss {:.04f}\\t Learning Rate {:.04f}\\t w0grad = {}\".format(\n",
    "        epoch + 1,\n",
    "        config['epochs'],\n",
    "        train_loss,\n",
    "        curr_lr,\n",
    "        w0grad))\n",
    "\n",
    "    valid_loss, valid_dist = validate_model(model, val_loader, decoder, phoneme_map=npLABELS)\n",
    "    scheduler.step(valid_loss)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    print(\"\\tVal Dist {:.04f}\\t Val Loss {:.04f}\".format(valid_dist, valid_loss))\n",
    "\n",
    "    wandb.log({\n",
    "        'train_loss': train_loss,\n",
    "        'valid_dist': valid_dist,\n",
    "        'valid_loss': valid_loss,\n",
    "        'lr': curr_lr,\n",
    "        'w0grad': w0grad,\n",
    "    })\n",
    "\n",
    "    save_model(model, optimizer, scheduler, ['valid_dist', valid_dist], epoch, epoch_model_path)\n",
    "    wandb.save(epoch_model_path)\n",
    "    print(\"Saved epoch model\")\n",
    "\n",
    "    if valid_dist <= best_lev_dist:\n",
    "        best_lev_dist = valid_dist\n",
    "        save_model(model, optimizer, scheduler, ['valid_dist', valid_dist], epoch, best_model_path)\n",
    "        wandb.save(best_model_path)\n",
    "        print(\"Saved best model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M2H4EEj-sD32"
   },
   "source": [
    "# Generate Predictions and Submit to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "2moYJhTWsOG-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 82/82 [01:28<00:00,  1.07s/it]\n"
     ]
    }
   ],
   "source": [
    "test_decoder = CTCBeamDecoder(LABELS, log_probs_input=True, **config['ctc_decoder_test'])\n",
    "\n",
    "results = []\n",
    "\n",
    "model.eval()\n",
    "print(\"Testing\")\n",
    "for data in tqdm(test_loader):\n",
    "\n",
    "    x, lx = data\n",
    "    x = x.reshape(x.shape, 1).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        h, lh = model(x, lx)\n",
    "    prediction_strings = decode_prediction(h, lh, test_decoder, PHONEME_MAP=npLABELS)\n",
    "\n",
    "    for pred in prediction_strings:\n",
    "        results.append(''.join(pred))\n",
    "\n",
    "    del x, lx, h, lh\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "d70dvu_lsMlv"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/pab/.kaggle/kaggle.json'\r\n",
      "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.13 / client 1.5.8)\r\n",
      "100%|█████████████████████████████████████████| 210k/210k [00:00<00:00, 301kB/s]\r\n",
      "Successfully submitted to Automatic Speech Recognition (ASR)"
     ]
    }
   ],
   "source": [
    "data_dir = './11-785-s23-hw3p2/test-clean/random_submission.csv'\n",
    "df = pd.read_csv(data_dir)\n",
    "df.label = results\n",
    "df.to_csv('submission.csv', index=False)\n",
    "\n",
    "!kaggle competitions submit -c 11-785-s23-hw3p2 -f submission.csv -m \"I made it!\""
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "gg3-yJ8tok34",
    "R9v5ewZDMpYA",
    "PB6eh3gnMUzy",
    "g3ZQ75OcMUz0",
    "kg82HXa3MUz1"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "bd385fe162c5ca0c84973b7dd5c518456272446b2b64e67c2a69f949ca7a1754"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
